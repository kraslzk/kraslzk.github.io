<a name="1026f25b"></a>
# Redis原理篇

<a name="b2a4a1c8"></a>
## 1、原理篇-Redis数据结构

<a name="c1b90c6f"></a>
### 1.1 Redis数据结构-SDS动态字符串

我们都知道Redis中保存的Key是字符串，value往往是字符串或者字符串的集合。可见字符串是Redis中最常用的一种数据结构。

不过Redis没有直接使用C语言中的字符串，因为C语言字符串存在很多问题：<br />获取字符串长度的需要通过运算<br />非二进制安全<br />不可修改<br />Redis构建了一种新的字符串结构，称为简单动态字符串（Simple Dynamic String），简称SDS。<br />例如，我们执行命令：<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702357235456-60cc8319-7569-40ae-bf15-6aa9634e5c11.png#averageHue=%23021f31&clientId=udab92dd4-9bf0-4&from=paste&height=65&id=u367acdd0&originHeight=81&originWidth=677&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=6616&status=done&style=none&taskId=ucf2cd7e1-8efc-40d4-8abe-ceab633fd08&title=&width=541.6)<br />那么Redis将在底层创建两个SDS，其中一个是包含“name”的SDS，另一个是包含“虎哥”的SDS。<br />Redis是C语言实现的，其中SDS是一个结构体，源码如下：<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702357265375-f3c447db-cc4b-4149-91a3-5f7cf70a8c8d.png#averageHue=%23f3f8ed&clientId=udab92dd4-9bf0-4&from=paste&height=166&id=u996e6e12&originHeight=208&originWidth=1087&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=33161&status=done&style=none&taskId=u3d05dfc5-3d60-449c-9a0c-b939079103c&title=&width=869.6)<br />例如，一个包含字符串“name”的sds结构如下：<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702357502132-e40f8d7d-7c1e-4514-bb39-adb4e28851ed.png#averageHue=%23fefdfc&clientId=udab92dd4-9bf0-4&from=paste&height=126&id=u29964a10&originHeight=158&originWidth=620&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=6161&status=done&style=none&taskId=u57679ac9-a07b-438b-828e-6e73569dc8d&title=&width=496)

SDS之所以叫做动态字符串，是因为它具备动态扩容的能力，例如一个内容为“hi”的SDS：![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702357580180-fce7d361-ac17-49eb-8e4d-6b47a3e74768.png#averageHue=%23f1f1f1&clientId=udab92dd4-9bf0-4&from=paste&height=90&id=u4aa9dc84&originHeight=113&originWidth=695&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=13627&status=done&style=none&taskId=uc80c0c5f-09f4-4a3c-a1d1-2143d83e247&title=&width=556)<br />假如我们要给SDS追加一段字符串“,Amy”，这里首先会申请新内存空间：<br />如果新字符串小于1M，则新空间为扩展后字符串长度的两倍+1；<br />如果新字符串大于1M，则新空间为扩展后字符串长度+1M+1。称为内存预分配。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702357600244-a299219c-d03a-48e0-97dc-5b1b6fc5c559.png#averageHue=%23e7e7e7&clientId=udab92dd4-9bf0-4&from=paste&height=81&id=ud380e3b3&originHeight=101&originWidth=1222&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=9835&status=done&style=none&taskId=u286d95a6-8b7e-4dc8-b233-b48b917b9d2&title=&width=977.6)<br />![](.%5C%E5%8E%9F%E7%90%86%E7%AF%87.assets%5C1653984822363.png#id=sasnm&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702357607767-1b3bbe81-c558-4452-af5f-1c256183b95f.png#averageHue=%23f2efef&clientId=udab92dd4-9bf0-4&from=paste&height=162&id=ufa5b1522&originHeight=203&originWidth=653&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=18526&status=done&style=none&taskId=u4cb080c4-84c6-48b6-a5f8-33f8a8655dc&title=&width=522.4)
<a name="890fd336"></a>
### 1.2 Redis数据结构-intset
IntSet是Redis中set集合的一种实现方式，基于整数数组来实现，并且具备长度可变、有序等特征。<br />结构如下：<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702357653637-0aef12ed-ebb2-4170-ae8b-5d2da4797aba.png#averageHue=%23f3f8ef&clientId=udab92dd4-9bf0-4&from=paste&height=131&id=u2911cf60&originHeight=164&originWidth=760&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=17347&status=done&style=none&taskId=u80f423cf-fc8f-4b15-b5ed-1b6529c370c&title=&width=608)<br />其中的encoding包含三种模式，表示存储的整数大小不同：<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702357666431-851ccb50-618a-46af-9d2f-0881d8df29dd.png#averageHue=%23f0f7eb&clientId=udab92dd4-9bf0-4&from=paste&height=135&id=u82298fa4&originHeight=169&originWidth=838&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=27545&status=done&style=none&taskId=u716b3fca-1f55-449d-b25c-17321e91beb&title=&width=670.4)<br />![](.%5C%E5%8E%9F%E7%90%86%E7%AF%87.assets%5C1653984942385.png#id=nYquL&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)为了方便查找，Redis会将intset中所有的整数按照升序依次保存在contents数组中，结构如图：<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702357746035-d5717d9a-16fb-4537-ab71-8cf6a06be7ac.png#averageHue=%23ebeaea&clientId=udab92dd4-9bf0-4&from=paste&height=255&id=u1f7c1284&originHeight=319&originWidth=1390&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=42199&status=done&style=none&taskId=ubebe4389-bbc2-49fc-b170-0e6d09aa3df&title=&width=1112)<br />现在，数组中每个数字都在int16_t的范围内，因此采用的编码方式是INTSET_ENC_INT16，每部分占用的字节大小为：<br />encoding：4字节<br />length：4字节<br />contents：2字节 * 3  = 6字节<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702357856389-dc299110-e924-4bb1-8177-1e530ba66fee.png#averageHue=%23f3f2f1&clientId=udab92dd4-9bf0-4&from=paste&height=111&id=u29a3d0da&originHeight=139&originWidth=1490&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=29119&status=done&style=none&taskId=u1a5ddb63-ff4c-4987-b4e6-e112504e87d&title=&width=1192)<br />我们向该其中添加一个数字：50000，这个数字超出了int16_t的范围，intset会自动升级编码方式到合适的大小。<br />以当前案例来说流程如下：

- 升级编码为INTSET_ENC_INT32, 每个整数占4字节，并按照新的编码方式及元素个数扩容数组
- 倒序依次将数组中的元素拷贝到扩容后的正确位置
- 将待添加的元素放入数组末尾
- 最后，将inset的encoding属性改为INTSET_ENC_INT32，将length属性改为4

![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702357918915-5f9fe74d-c727-4052-ae45-dab935f6a8e9.png#averageHue=%23fefdfd&clientId=udab92dd4-9bf0-4&from=paste&height=94&id=u81210849&originHeight=118&originWidth=1112&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=9927&status=done&style=none&taskId=ue224afd8-a880-441e-83a8-7f23129e5d1&title=&width=889.6)<br />源码如下：<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702357974295-0f12143a-ee50-4f60-831c-19ee92e4b0af.png#averageHue=%23f2f8ee&clientId=udab92dd4-9bf0-4&from=paste&height=484&id=u40afbb11&originHeight=605&originWidth=790&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=74494&status=done&style=none&taskId=u66838ee6-994f-4005-b525-d0ddf110d56&title=&width=632)<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702357981136-c13e9a74-8388-4292-9122-1b7f7f30ad7c.png#averageHue=%23f2f8ee&clientId=udab92dd4-9bf0-4&from=paste&height=490&id=u79b68201&originHeight=613&originWidth=887&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=84034&status=done&style=none&taskId=uc4634679-88ca-4296-b973-66afec5e0e4&title=&width=709.6)<br />小总结：<br />Intset可以看做是特殊的整数数组，具备一些特点：

- Redis会确保Intset中的元素唯一、有序
- 具备类型升级机制，可以节省内存空间
- 底层采用二分查找方式来查询
<a name="3aec352d"></a>
### 1.3 Redis数据结构-Dict
我们知道Redis是一个键值型（Key-Value Pair）的数据库，我们可以根据键实现快速的增删改查。而键与值的映射关系正是通过Dict来实现的。<br />Dict由三部分组成，分别是：哈希表（DictHashTable）、哈希节点（DictEntry）、字典（Dict）<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702358285496-55286ee8-858e-481d-8da4-cffd36e4cbdc.png#clientId=udab92dd4-9bf0-4&from=paste&height=261&id=u4cfc13db&originHeight=326&originWidth=1345&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=81107&status=done&style=none&taskId=uab6a4824-a902-47ab-a763-0911c5f6732&title=&width=1076)<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702358558479-37f05723-52a8-40f8-8a63-5822799621d0.png#clientId=udab92dd4-9bf0-4&from=paste&height=140&id=u85ab8aca&originHeight=175&originWidth=977&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=29549&status=done&style=none&taskId=u21ed2b7b-d316-4be9-ae68-486c9fda06d&title=&width=781.6)<br />当我们向Dict添加键值对时，Redis首先根据key计算出hash值（h），然后利用 h & sizemask来计算元素应该存储到数组中的哪个索引位置。我们存储k1=v1，假设k1的哈希值h =1，则1&3 =1，因此k1=v1要存储到数组角标1位置。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702358371577-55e1c4a7-afe6-4d90-8bac-71f89875b797.png#clientId=udab92dd4-9bf0-4&from=paste&height=215&id=ua69cbfc6&originHeight=269&originWidth=1432&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=36954&status=done&style=none&taskId=u91010045-98f9-48c6-ab6b-5ef6260e3f1&title=&width=1145.6)![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702358657775-ec70805f-f997-42db-ace4-f808144cf1c7.png#clientId=udab92dd4-9bf0-4&from=paste&height=334&id=u5f3f2c32&originHeight=417&originWidth=1155&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=91722&status=done&style=none&taskId=uc0bc95fa-3c6e-4a10-ae22-405bc985151&title=&width=924)<br />**Dict的扩容**<br />Dict中的HashTable就是数组结合单向链表的实现，当集合中元素较多时，必然导致哈希冲突增多，链表过长，则查询效率会大大降低。<br />Dict在每次新增键值对时都会检查负载因子（LoadFactor = used/size） ，满足以下两种情况时会触发哈希表扩容：<br />哈希表的 LoadFactor >= 1，并且服务器没有执行 BGSAVE 或者 BGREWRITEAOF 等后台进程；<br />哈希表的 LoadFactor > 5 ；<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702362969949-b9178058-bef1-471a-9780-52ae2f0063d4.png#clientId=udab92dd4-9bf0-4&from=paste&height=275&id=u7c1b5dcf&originHeight=344&originWidth=1009&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=52287&status=done&style=none&taskId=u628e276b-529b-4d6a-9abf-c82c491cc5a&title=&width=807.2)<br />**Dict的rehash**<br />不管是扩容还是收缩，必定会创建新的哈希表，导致哈希表的size和sizemask变化，而key的查询与sizemask有关。因此必须对哈希表中的每一个key重新计算索引，插入新的哈希表，这个过程称为rehash。过程是这样的：

-  计算新hash表的realeSize，值取决于当前要做的是扩容还是收缩： 
   - 如果是扩容，则新size为第一个大于等于dict.ht[0].used + 1的2^n
   - 如果是收缩，则新size为第一个大于等于dict.ht[0].used的2^n （不得小于4）
-  按照新的realeSize申请内存空间，创建dictht，并赋值给dict.ht[1] 
-  设置dict.rehashidx = 0，标示开始rehash 
-  将dict.ht[0]中的每一个dictEntry都rehash到dict.ht[1] 
-  将dict.ht[1]赋值给dict.ht[0]，给dict.ht[1]初始化为空哈希表，释放原来的dict.ht[0]的内存 
-  将rehashidx赋值为-1，代表rehash结束 
-  在rehash过程中，新增操作，则直接写入ht[1]，查询、修改和删除则会在dict.ht[0]和dict.ht[1]依次查找并执行。这样可以确保ht[0]的数据只减不增，随着rehash最终为空 

整个过程可以描述成：<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702363170191-c2a43c97-ad58-473c-a3e8-6e7af9b6cf15.png#clientId=udab92dd4-9bf0-4&from=paste&height=513&id=u0d35651c&originHeight=641&originWidth=1182&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=49973&status=done&style=none&taskId=ua65868bd-9608-4e1e-9c8a-df30dc3038f&title=&width=945.6)<br />小总结：<br />Dict的结构：

- 类似java的HashTable，底层是数组加链表来解决哈希冲突
- Dict包含两个哈希表，ht[0]平常用，ht[1]用来rehash

Dict的伸缩：

- 当LoadFactor大于5或者LoadFactor大于1并且没有子进程任务时，Dict扩容
- 当LoadFactor小于0.1时，Dict收缩
- 扩容大小为第一个大于等于used + 1的2^n
- 收缩大小为第一个大于等于used 的2^n
- Dict采用渐进式rehash，每次访问Dict时执行一次rehash
- rehash时ht[0]只减不增，新增操作只在ht[1]执行，其它操作在两个哈希表
<a name="82eb0df0"></a>
### 1.4 Redis数据结构-ZipList
ZipList 是一种特殊的“双端链表” ，由一系列特殊编码的连续内存块组成。可以在任意一端进行压入/弹出操作, 并且该操作的时间复杂度为 O(1)。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702363336065-0dc23d4d-06c8-44e3-bb80-76b3b7155f01.png#clientId=udab92dd4-9bf0-4&from=paste&height=369&id=uf8cc633a&originHeight=461&originWidth=1106&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=22174&status=done&style=none&taskId=u865135ac-10c2-468a-8a23-b7a336cdfb6&title=&width=884.8)<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702363400548-ef18b68e-6ced-4a4a-8f65-e7ae58ab56c7.png#clientId=udab92dd4-9bf0-4&from=paste&height=53&id=u3902d71d&originHeight=66&originWidth=983&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=2262&status=done&style=none&taskId=uc167c495-73ba-4cd6-ad97-9a50b9c2119&title=&width=786.4)

| **属性** | **类型** | **长度** | **用途** |
| --- | --- | --- | --- |
| zlbytes | uint32_t | 4 字节 | 记录整个压缩列表占用的内存字节数 |
| zltail | uint32_t | 4 字节 | 记录压缩列表表尾节点距离压缩列表的起始地址有多少字节，通过这个偏移量，可以确定表尾节点的地址。 |
| zllen | uint16_t | 2 字节 | 记录了压缩列表包含的节点数量。 最大值为UINT16_MAX （65534），如果超过这个值，此处会记录为65535，但节点的真实数量需要遍历整个压缩列表才能计算得出。 |
| entry | 列表节点 | 不定 | 压缩列表包含的各个节点，节点的长度由节点保存的内容决定。 |
| zlend | uint8_t | 1 字节 | 特殊值 0xFF （十进制 255 ），用于标记压缩列表的末端。 |

**ZipListEntry**<br />ZipList 中的Entry并不像普通链表那样记录前后节点的指针，因为记录两个指针要占用16个字节，浪费内存。而是采用了下面的结构：<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702363804399-b4909566-49bb-4eb5-a986-0ae9baac828a.png#clientId=udab92dd4-9bf0-4&from=paste&height=46&id=ucf4ef6e8&originHeight=58&originWidth=652&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=2079&status=done&style=none&taskId=uf20944fd-e285-444e-8d50-d6da5aba757&title=&width=521.6)

-  previous_entry_length：前一节点的长度，占1个或5个字节。 
   - 如果前一节点的长度小于254字节，则采用1个字节来保存这个长度值
   - 如果前一节点的长度大于254字节，则采用5个字节来保存这个长度值，第一个字节为0xfe，后四个字节才是真实长度数据
-  encoding：编码属性，记录content的数据类型（字符串还是整数）以及长度，占用1个、2个或5个字节 
-  contents：负责保存节点的数据，可以是字符串或整数 

ZipList中所有存储长度的数值均采用小端字节序，即低位字节在前，高位字节在后。例如：数值0x1234，采用小端字节序后实际存储值为：0x3412

**Encoding编码**<br />ZipListEntry中的encoding编码分为字符串和整数两种：<br />字符串：如果encoding是以“00”、“01”或者“10”开头，则证明content是字符串

| **编码** | **编码长度** | **字符串大小** |
| --- | --- | --- |
| &#124;00pppppp&#124; | 1 bytes | <= 63 bytes |
| &#124;01pppppp&#124;qqqqqqqq&#124; | 2 bytes | <= 16383 bytes |
| &#124;10000000&#124;qqqqqqqq&#124;rrrrrrrr&#124;ssssssss&#124;tttttttt&#124; | 5 bytes | <= 4294967295 bytes |

例如，我们要保存字符串：“ab”和 “bc”<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702364306662-463d1e6b-3b88-459b-b691-bbbf20ff03d1.png#averageHue=%23f6f4f4&clientId=udab92dd4-9bf0-4&from=paste&height=162&id=u81baafa3&originHeight=202&originWidth=1165&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=14458&status=done&style=none&taskId=ua61a9cc4-24d3-4bee-a3ac-5bc48bfde15&title=&width=932)<br />ZipListEntry中的encoding编码分为字符串和整数两种：

- 整数：如果encoding是以“11”开始，则证明content是整数，且encoding固定只占用1个字节
| **编码** | **编码长度** | **整数类型** |
| --- | --- | --- |
| 11000000 | 1 | int16_t（2 bytes） |
| 11010000 | 1 | int32_t（4 bytes） |
| 11100000 | 1 | int64_t（8 bytes） |
| 11110000 | 1 | 24位有符整数(3 bytes) |
| 11111110 | 1 | 8位有符整数(1 bytes) |
| 1111xxxx | 1 | **直接在xxxx位置保存数值，范围从0001~1101，减1后结果为实际值** |

![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702364597981-7ac102b9-eaf2-4867-8edc-60207011d579.png#clientId=udab92dd4-9bf0-4&from=paste&height=150&id=uf4af7f5b&originHeight=187&originWidth=941&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=13427&status=done&style=none&taskId=ub02793ed-8449-412a-b3f0-4405bf2cd17&title=&width=752.8)<br />![](.%5C%E5%8E%9F%E7%90%86%E7%AF%87.assets%5C1653986282879.png#id=eBK4Q&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702364577931-f38a8c28-bbb0-402b-b25d-9d8f027e4214.png#clientId=udab92dd4-9bf0-4&from=paste&height=158&id=u808aeddd&originHeight=197&originWidth=577&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=5805&status=done&style=none&taskId=u157ef8c3-2a2f-4d8c-883f-1d43b54164e&title=&width=461.6)
<a name="e2edcfed"></a>
### 1.5 Redis数据结构-ZipList的连锁更新问题
ZipList的每个Entry都包含previous_entry_length来记录上一个节点的大小，长度是1个或5个字节：<br />如果前一节点的长度小于254字节，则采用1个字节来保存这个长度值<br />如果前一节点的长度大于等于254字节，则采用5个字节来保存这个长度值，第一个字节为0xfe，后四个字节才是真实长度数据<br />现在，假设我们有N个连续的、长度为250~253字节之间的entry，因此entry的previous_entry_length属性用1个字节即可表示，如图所示：<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702364915012-b3d769db-be8a-48fd-b07c-5533ed78bae9.png#clientId=udab92dd4-9bf0-4&from=paste&height=128&id=u0105790f&originHeight=160&originWidth=1245&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=12175&status=done&style=none&taskId=u7a305f46-d9a1-4560-a9df-f7baec4f156&title=&width=996)<br />ZipList这种特殊情况下产生的连续多次空间扩展操作称之为连锁更新（Cascade Update）。新增、删除都可能导致连锁更新的发生。<br />**小总结：**<br />**ZipList特性：**

- 压缩列表的可以看做一种**连续内存空间**的"双向链表"
- 列表的节点之间不是通过指针连接，而是**记录上一节点和本节点长度来寻址，内存占用较低**
- 如果列表数据过多，导致链表过长，可能影响查询性能
- 增或删较大数据时有可能发生**连续更新问题**

<a name="b9d00b7d"></a>
### 1.6 Redis数据结构-QuickList
问题1：ZipList虽然节省内存，但**申请内存必须是连续空间**，如果内存占用较多，申请内存效率很低。怎么办？<br />	答：为了缓解这个问题，我们必须**限制ZipList的长度和entry大小**。

问题2：但是我们要存储大量数据，**超出了ZipList最佳的上限**该怎么办？<br />	答：我们可以创建**多个ZipList来分片存储数据**。

问题3：数据拆分后比较**分散，不方便管理和查找**，这多个ZipList如何建立联系？<br />	答：Redis在3.2版本引入了新的数据结构**QuickList**，它是一个双端链表，只不过链表中的**每个节点都是一个ZipList**。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702365140819-b9c48d8f-d7ae-45c4-8ec7-b52091b4e55d.png#clientId=udab92dd4-9bf0-4&from=paste&height=252&id=u3998615b&originHeight=315&originWidth=1306&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=32012&status=done&style=none&taskId=ub7256d19-9616-45fe-9322-ef7a93c0256&title=&width=1044.8)<br />为了避免QuickList中的**每个ZipList中entry**过多，Redis提供了一个配置项：list-max-ziplist-size来限制。<br />如果值为正，则代表ZipList的允许的entry个数的最大值<br />如果值为负，则代表ZipList的最大内存大小，分5种情况：

- -1：每个ZipList的内存占用不能超过4kb
- -2：每个ZipList的内存占用不能超过8kb
- -3：每个ZipList的内存占用不能超过16kb
- -4：每个ZipList的内存占用不能超过32kb
- -5：每个ZipList的内存占用不能超过64kb

其默认值为 -2：<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702365220437-9329fefa-2027-44b0-9397-af23c8069df9.png#clientId=udab92dd4-9bf0-4&from=paste&height=91&id=u142a6081&originHeight=114&originWidth=803&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=10829&status=done&style=none&taskId=ud8451be9-fac6-40d4-9f0f-5c90bdfaa5c&title=&width=642.4)<br />以下是QuickList的和QuickListNode的结构源码：<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702365324202-9a34862f-42f8-4264-9258-ff41980a01cb.png#clientId=udab92dd4-9bf0-4&from=paste&height=303&id=u9679a5e3&originHeight=410&originWidth=1048&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=77739&status=done&style=none&taskId=u63eec6a7-53fa-4594-8c3b-06b457d1ca2&title=&width=775.4000244140625)<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702365421420-b1490e01-5c80-412d-9824-b582049c819f.png#clientId=udab92dd4-9bf0-4&from=paste&height=375&id=TWABv&originHeight=469&originWidth=1074&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=34203&status=done&style=none&taskId=ud0003534-0018-4490-b703-ea947659a03&title=&width=859.2)<br />总结：<br />QuickList的特点：

- 是一个节点为ZipList的双端链表
- 节点采用ZipList，解决了传统链表的内存占用问题
- 控制了ZipList大小，**解决连续内存空间申请效率问题**
- 中间节点可以压缩，进一步节省了内存
<a name="7e1e5e74"></a>
### 1.7 Redis数据结构-SkipList跳表
跳表：<br />(1)跳跃表的每一层都是一条**有序的链表。**<br />**(2)维护了多条节点路径。**<br />(3)最底层的链表包含所有元素。<br />(4)跳跃表的空间复杂度为 **O(n)**。<br />(5)跳跃表支持平均**O(logN)**、最坏**O(N)**复杂度的节点查找，还可以通过**顺序性操作**来批量处理节点。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702365510418-0dc70392-6cff-4450-bbc2-39929e8a7998.png#averageHue=%23f8f8f7&clientId=udab92dd4-9bf0-4&from=paste&height=273&id=irpJB&originHeight=341&originWidth=1148&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=24059&status=done&style=none&taskId=ub1c5d7c7-9cee-4017-b54c-f61bc8c3305&title=&width=918.4)<br />**SkipList的特点：**

- 跳跃表是一个双向链表，每个节点都包含score和ele值
- 节点按照score值排序，score值一样则按照ele字典排序
- 每个节点都可以包含多层指针，层数是1到32之间的随机数
- 不同层指针到下一个节点的跨度不同，层级越高，跨度越大
- 增删改查效率与红黑树基本一致，实现却更简单
- 跳表的查找会从顶层链表的头部元素开始，然后遍历该链表，直到找到元素大于或等于目标元素的节点，如果当前元素正好等于目标，那么就直接返回它。如果当前元素小于目标元素，那么就垂直下降到下一层继续搜索，如果当前元素大于目标或到达链表尾部，则移动到前一个节点的位置，然后垂直下降到下一层。正因为 Skiplist 的搜索过程会不断地从一层跳跃到下一层的，所以被称为跳跃表。

SkipList（跳表）首先是链表，但与传统链表相比有几点差异：

- 元素按照**升序排列**存储
- 节点可能包含**多个指针**，指针**跨度不同**。

每次创建一个新跳跃表节点的时候，程序根据幂次定律(power law，越大的数出现的概率越小)**随机**生成一个介于0和31之间的值作为level数组的大小，这个大小就是层的“**高度**”。<br />**后退指针**backword支持redis的zset按分数从高到低从后往前返回元素。<br />**层的跨度**(level[i].span属性)用于记录两个节点之间的距离：<br />      两个节点之间的跨度越大，它们相距得就越远。<br />      指向NULL的所有前进指针的跨度都为0，因为它们没有连向任何节点。<br />  遍历操作只使用前进指针就可以完成了，**跨度实际上是用来计算排位(rank)**的：在**查找**某个节点的过程中，将**沿途访问过的所有层的跨度累计起来，得到的结果就是目标节点在跳跃表中的排位**。

![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702365546226-163ae521-2eb4-4bd6-90d9-c159b82fda2a.png#averageHue=%23dcbd75&clientId=udab92dd4-9bf0-4&from=paste&height=286&id=ufb1c794d&originHeight=358&originWidth=1096&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=46882&status=done&style=none&taskId=u0c46568e-278f-4bf5-bbc5-3403744e70c&title=&width=876.8)<br />![](.%5C%E5%8E%9F%E7%90%86%E7%AF%87.assets%5C1653986813240.png#id=fruHU&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702365787214-beb874e9-bcb2-465a-8643-f49790f11291.png#averageHue=%23ecebeb&clientId=udab92dd4-9bf0-4&from=paste&height=342&id=u85ad6e99&originHeight=428&originWidth=1107&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=22291&status=done&style=none&taskId=u63fda7cb-5e31-4682-987a-67e7e60c0c9&title=&width=885.6)<br />**SkipList创建：**初始化head头指针，创建32（最大层数）层链表的头节点。<br />**SkipList插入**：新创建的节点初始化随机层数，接着就是把节点插入每一层的链表

- 找到新节点在每一层的上一个节点（即：对于level0，应该先找到节点9；对于level1，应该先找到节点8）
- 将新节点插入到每一层的上一个节点和下一个节点之间 
- 在插入新节点之后，我们需要**计算新节点在每一层的span**，另外，在插入新节点之后，新节点的**上一个节点的span也会发生变化**
   - 底层其实是没有这个问题的，因为底层压根就没有跳嘛。。。所有节点在底层都是直接相邻的，所以span都是1。
- <br />

![image.png](https://cdn.nlark.com/yuque/0/2024/png/40745172/1705128774900-33ec6cd0-b7cf-4315-94ac-fa7e2e3f513e.png#clientId=u13e0bebf-9e07-4&from=paste&height=121&id=u8e12a651&originHeight=151&originWidth=1519&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=45813&status=done&style=none&taskId=u33eb0462-2f99-499b-a4f2-ae5ac849b42&title=&width=1215.2)<br />**详情参考：**[**https://blog.csdn.net/u013536232/article/details/105476382**](https://blog.csdn.net/u013536232/article/details/105476382)

<a name="0f6d19f7"></a>
### 1.7 Redis数据结构-RedisObject
Redis中的任意数据类型的键和值都会被封装为一个RedisObject，也叫做Redis对象。<br />1、什么是redisObject：<br />从Redis的使用者的角度来看，⼀个Redis节点包含多个database（非cluster模式下默认是16个，cluster模式下只能是1个），而一个database维护了从key space到object space的映射关系。这个映射关系的key是string类型，⽽value可以是多种数据类型，比如：<br />string, list, hash、set、sorted set等。我们可以看到，key的类型固定是string，而value可能的类型是多个。<br />⽽从Redis内部实现的⾓度来看，database内的这个**映射关系是用⼀个dict来维护的**。dict的**key**固定用⼀种数据结构来表达就够了，这就是**动态字符串sds**。而value则比较复杂，为了在同⼀个dict内能够**存储不同类型的value**，这就需要⼀个**通⽤的数据结构**，这个通用的数据结构就是robj，全名是redisObject。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702366021228-07dafe10-f0be-47e6-9aab-c8017dba1561.png#averageHue=%23f3f1ef&clientId=udab92dd4-9bf0-4&from=paste&height=247&id=ud6a0fa02&originHeight=309&originWidth=941&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=80870&status=done&style=none&taskId=u2f903160-6b6f-45ae-86aa-0d8c7e5ed0c&title=&width=752.8)<br />**Redis的编码方式**<br />Redis中会根据存储的数据类型不同，选择不同的编码方式，共包含11种不同类型：

| **编号** | **编码方式** | **说明** |
| --- | --- | --- |
| 0 | OBJ_ENCODING_RAW | raw编码动态字符串 |
| 1 | OBJ_ENCODING_INT | long类型的整数的字符串 |
| 2 | OBJ_ENCODING_HT | hash表（字典dict） |
| 3 | OBJ_ENCODING_ZIPMAP | 已废弃 |
| 4 | OBJ_ENCODING_LINKEDLIST | 双端链表 |
| 5 | OBJ_ENCODING_ZIPLIST | 压缩列表 |
| 6 | OBJ_ENCODING_INTSET | 整数集合 |
| 7 | OBJ_ENCODING_SKIPLIST | 跳表 |
| 8 | OBJ_ENCODING_EMBSTR | embstr的动态字符串 |
| 9 | OBJ_ENCODING_QUICKLIST | 快速列表 |
| 10 | OBJ_ENCODING_STREAM | Stream流 |

**五种数据结构**<br />Redis中会根据存储的数据类型不同，选择不同的编码方式。每种数据类型的使用的编码方式如下：

| **数据类型** | **编码方式** |
| --- | --- |
| OBJ_STRING | int、embstr、raw |
| OBJ_LIST | LinkedList和ZipList(3.2以前)、QuickList（3.2以后） |
| OBJ_SET | intset、HT |
| OBJ_ZSET | ZipList、HT、SkipList |
| OBJ_HASH | ZipList、HT |

<a name="a710792e"></a>
### 1.8 Redis数据结构-String
String是Redis中最常见的数据存储类型：<br />其基本编码方式是**RAW**，基于简单动态字符串（SDS）实现，存储上限为**512mb**。<br />如果存储的SDS长度小于44字节，则会采用**EMBSTR**编码，此时object head与SDS是一段连续空间。申请内存时<br />只需要**调用一次内存分配函数，效率更高**。<br />_Redis 在创建一个 String 类型的 value, 需要分配内存有 2 个, redisObject 本身 + 存储内容的 sds。_<br />_分配 redisObject 自身需要 (4 + 4 + 24)bit + 4 字节 + 8 字节 = 16 个字节_<br />_分配一个最少内存的 sds, 也就是 sds8 需要 1 (uint8_t len) + 1 (uint8_t alloc) + 1 (unsigned char) + 1 (别忘了, char[] 系统会在后面自动填充一个 \0) = 4 个字节 (sds5 会被转换为 sds8 进行分配)_<br />_这样**创建一个不包含任何内容的 String 类型的 value**, 需要 16 字节的 redisObject + 4 字节的 sds8 =** 20 字节**的内存。c语言的内存分配器malloc在内存分配的时候，按照**2的n次方**进行分配。所以在为一个不包含任何内容的 String 类型的 value (20 个字节) 进行内存分配时,** 需要分配 32 个字节**, **多分配了 12 个字节**。上面讨论的是 sds8 的 _**_char[] buf_**_ 为空的情况, 实际中, sds8 是一定会有内容的, 如果这时, 这些内容的大小在 12 个字节以内,那么我们创建一个 String 类型的 value, 只用到了一次内存分配就完成了。_<br />**_在 Redis 中, 认为一次分配的内存大于 64 字节, 是一个得不偿失的行为, 大内存的申请消耗的时间更长等。超过 64 字节的内存分配, 会多次进行。_**<br />embstr和raw编码分配内存的区别：

1. **embstr: redisObject + sds, 内存是一起分配的, 只需要一次内存分配, 同时内存是相连在一起。**
2. **raw : redisObject + sds 是分开分配的, 需要 2 次内存分配以上, 内存也不一定相连在一起。**

_分配一个不含任何内容的 **redisObject + sds 需要 20 字节, 最大一次分配 64 字节, 64 - 20 = 44 字节**, 所以在 Redis 中创建一个 String 对象：_<br />**String 的内容长度小于等于 44 字节, 编码为 embstr**<br />**String 的内容长度大于 44 字节, 编码为 raw**

（1）底层实现⽅式：动态字符串sds 或者 long<br />String的内部存储结构⼀般是sds（Simple Dynamic String，可以动态扩展内存），但是如果⼀个String类型的value的值是数字，那么Redis内部会把它转成long类型来存储，从⽽减少内存的使用。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702366254509-078e9c75-0867-4d78-9490-82b371942d0c.png#averageHue=%23f9f9f9&clientId=udab92dd4-9bf0-4&from=paste&height=228&id=u9f560816&originHeight=285&originWidth=1063&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=11798&status=done&style=none&taskId=u6eb6f3bb-05d7-450d-8184-9840d779df0&title=&width=850.4)<br />如果存储的字符串是整数值，并且大小在**LONG_MAX范围内**，则会采用**INT编码**：直接将**数据保存**在RedisObject的**ptr指针**位置（刚好8字节），**不再需要SDS**了。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702366306112-2978ae37-a6c8-43d9-97c8-988fba541a00.png#averageHue=%23f6faf3&clientId=udab92dd4-9bf0-4&from=paste&height=255&id=u18a8f3fb&originHeight=319&originWidth=1550&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=66394&status=done&style=none&taskId=u31a08109-7f6a-450d-918c-50be0dafb84&title=&width=1240)<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702366380780-9933c076-d4d9-4d3d-91aa-cb3b1cb07aa9.png#averageHue=%23eeeded&clientId=udab92dd4-9bf0-4&from=paste&height=110&id=ucfb34ecc&originHeight=137&originWidth=1055&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=9688&status=done&style=none&taskId=u1ca8833e-68aa-4d9f-b71e-8acb1767105&title=&width=844)<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702366387055-22f1aba8-79bf-4581-bd17-116994dd2b37.png#averageHue=%23f4f2f1&clientId=udab92dd4-9bf0-4&from=paste&height=390&id=u253c6e4b&originHeight=488&originWidth=1122&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=33917&status=done&style=none&taskId=u6ebe33e4-a794-4348-8b38-e35ad0c22a4&title=&width=897.6)<br />确切地说，**String在Redis中是⽤⼀个robj来表示的**。<br />用来表示String的robj可能编码成3种内部表⽰：OBJ_ENCODING_RAW，OBJ_ENCODING_EMBSTR，OBJ_ENCODING_INT。<br />其中前两种编码使⽤的是sds来存储，最后⼀种**OBJ_ENCODING_INT编码直接把string存成了long型**。<br />在对string进行**incr, decr**等操作的时候，如果它内部是**OBJ_ENCODING_INT编码，那么可以直接行加减**操作；如果它内部是OBJ_ENCODING_RAW或OBJ_ENCODING_EMBSTR编码，那么Redis会先试图把**sds存储的字符串转成long型**，如果能转成功，再进行加减操作。对⼀个**内部表示成long型的string执行append, setbit, getrange这些命令，针对的仍然是string的值（即⼗进制表示的字符串）**，而不是针对内部表⽰的long型进⾏操作。比如字符串”32”，如果按照字符数组来解释，它包含两个字符，它们的ASCII码分别是0x33和0x32。当我们执行命令setbit key 7 0的时候，相当于把字符0x33变成了0x32，这样字符串的值就变成了”22”。⽽如果将字符串”32”按照内部的64位long型来解释，那么它是0x0000000000000020，在这个基础上执⾏setbit位操作，结果就完全不对了。因此，**在这些命令的实现中，会把long型先转成字符串再进行相应的操作。**
<a name="5f7c3140"></a>
### 1.9 Redis数据结构-List
Redis的List类型可以从首、尾操作列表中的元素<br />哪一个数据结构能满足上述特征？

- LinkedList ：普通链表，可以从双端访问，内存占用较高，内存碎片较多
- ZipList ：压缩列表，可以从双端访问，内存占用低，存储上限低
- QuickList：LinkedList + ZipList，可以从双端访问，内存占用较低，包含多个ZipList，存储上限高

Redis的List结构类似一个双端链表，可以从首、尾操作列表中的元素。

在3.2版本之前，Redis采用ZipList和LinkedList来实现List，当元素数量小于512并且元素大小小于64字节时采用ZipList编码，超过则采用LinkedList编码。<br />在3.2版本之后，Redis统一采用**QuickList**来实现List：<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702366797138-333ccf6b-1e20-4125-be0e-008149d5d56c.png#averageHue=%23e7e6e5&clientId=udab92dd4-9bf0-4&from=paste&height=282&id=uafadd964&originHeight=352&originWidth=1114&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=29584&status=done&style=none&taskId=u9e78f939-c0b8-48a1-9e17-03e254c0b9e&title=&width=891.2)<br />![](.%5C%E5%8E%9F%E7%90%86%E7%AF%87.assets%5C1653987313461.png#id=Stkdn&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
<a name="b0e761ec"></a>
### 2.0 Redis数据结构-Set结构
Set是Redis中的单列集合，满足下列特点：

- 不保证有序性
- 保证元素唯一
- 求交集、并集、差集

Set对查询元素的效率要求非常高<br />HashTable，也就是Redis中的Dict，Set是Redis中的集合，不一定确保元素有序，可以满足元素唯一、查询效率要求极高。<br />为了查询效率和唯一性，**set采用HT编码（Dict）**。Dict中的**key用来存储元素**，**value统一为null**。<br />当**存储的所有数据都是整数**，并且元素数量**不超过set-max-intset-entries**时，Set会**采用IntSet编码**，以节省内存<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702366894791-b6244965-f33d-458b-8297-2a2d0fb5c37a.png#averageHue=%23f3f5eb&clientId=udab92dd4-9bf0-4&from=paste&height=293&id=ud3d45520&originHeight=366&originWidth=1099&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=59521&status=done&style=none&taskId=u3de1a2bd-4043-4619-a35d-97dd62380f0&title=&width=879.2)<br />结构如下：<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702367066204-0e929bdd-f3be-4c87-90de-7373ced2827c.png#averageHue=%23eeedec&clientId=udab92dd4-9bf0-4&from=paste&height=295&id=ubb6f5ca7&originHeight=369&originWidth=1092&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=30879&status=done&style=none&taskId=ueb543ce1-922c-4b36-8542-2d90f812283&title=&width=873.6)
<a name="116bd46a"></a>
### 2.1、Redis数据结构-ZSet
参考：[https://blog.csdn.net/weichi7549/article/details/107335133/](https://blog.csdn.net/weichi7549/article/details/107335133/)<br />ZSet也就是SortedSet，其中每一个元素都需要指定一个score值和member值：

- 可以根据score值排序
- member必须唯一
- 可以根据member查询分数

因此，zset底层数据结构必须满足**键值存储**、**键必须唯一**、**可排序**这几个需求。使用**HT+SkipList，元素较少时使用ZipList。**

- SkipList：可以排序，以score进行查询，并且可以同时存储score和ele值（member），但是不能根据键查询分数，因为需要遍历链表查找，也不支持键唯一。
- HT（Dict）：可以键值存储，并且可以根据key找value，但不能排序。

![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702367154109-5239b646-6a23-4141-85d0-58334aee136b.png#averageHue=%23f5f9f0&clientId=udab92dd4-9bf0-4&from=paste&height=166&id=u1a490fca&originHeight=192&originWidth=868&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=26058&status=done&style=none&taskId=u2995dd5f-dbf5-4d2b-8394-9b679229bee&title=&width=748.4000244140625)<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702367292293-7fb508a5-7d1c-4e76-8c1e-b12712ead45c.png#averageHue=%23f4f4f3&clientId=udab92dd4-9bf0-4&from=paste&height=478&id=OltIJ&originHeight=597&originWidth=1054&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=38487&status=done&style=none&taskId=u48c69eca-32c2-4e33-99bb-6ebd14412cc&title=&width=843.2)<br />几个查询命令：

- zrevrank由数据查询它对应的排名，skipList中level数组记录的span就是计算排名的。
- zscore由数据查询它对应的分数，在hash字典dict中查找返回。
- zrevrange根据一个排名范围，查询排名在这个范围内的数据。
- zrevrangebyscore根据分数区间查询数据集合，是一个skiplist所支持的典型的范围查找（score相当于key，数据相当于value）。

当数据多的时候，sorted set是由一个**dict** + 一个**skiplist**来实现的。简单来讲，dict用来查询数据到分数的对应关系，而skiplist用来根据分数查询数据（可能是范围查找）。

- zscore的查询，不是由skiplist来提供的，而是由那个dict来提供的。
- 为了支持排名(rank)，Redis里对skiplist做了扩展，使得根据排名能够快速查到数据，或者根据分数查到数据之后，也同时很容易获得排名。而且，根据排名的查找，时间复杂度也为O(log n)。
- zrevrange的查询，是根据排名查数据，由扩展后的skiplist来提供。
- zrevrank是先在dict中由数据查到分数，再拿分数到skiplist中去查找，查到后也同时获得了排名。

![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702369475699-00dd05e4-8d88-4a05-9ec8-bf2780898e9b.png#averageHue=%23fbfbfb&clientId=udab92dd4-9bf0-4&from=paste&id=u163ea640&originHeight=716&originWidth=1177&originalType=url&ratio=1.25&rotation=0&showTitle=false&size=351732&status=done&style=none&taskId=u23d3a878-208c-48e7-b3ee-24e777c8df2&title=)<br />当**元素数量不多**时，HT和SkipList的优势不明显，而且更耗内存。因此zset还会**采用ZipList结构来节省内存**，不过需要同时满足两个条件：

- 元素数量小于zset_max_ziplist_entries，默认值128
- 每个元素都小于zset_max_ziplist_value字节，默认值64

**ziplist本身没有排序功能，而且没有键值对的概念，因此需要有zset通过编码实现**：

- ZipList是连续内存，因此**score和element是紧挨在一起的两个entry， element在前，score在后**
- score**越小越接近队首**，score越大越接近队尾，按照score值**升序排列**

![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702369715545-4e2d46d5-d2c5-48ab-96ad-097612965108.png#averageHue=%23f5f4f4&clientId=udab92dd4-9bf0-4&from=paste&height=205&id=uce79a6f1&originHeight=256&originWidth=1053&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=13301&status=done&style=none&taskId=u86a9d416-5f6c-49c2-83c0-3e37f2857d2&title=&width=842.4)
<a name="6e2d007e"></a>
### 2.2 、Redis数据结构-Hash
Hash结构与Redis中的Zset非常类似：

- 都是键值存储
- 都需求根据键获取值
- 键必须唯一

区别如下：

- zset的键是member，值是score；hash的键和值都是任意值
- zset要根据score排序；hash则无需排序

<br />Hash结构默认采用**ZipList**编码，用以节省内存。 ZipList中相邻的两个entry 分别保存field和value<br />当数据量较大时，Hash结构会转为HT编码，也就是**Dict**，触发条件有两个：

- ZipList中的元素数量超过了hash-max-ziplist-entries（默认512）
- ZipList中的任意entry大小超过了hash-max-ziplist-value（默认64字节）

![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702369860961-0f15fba7-1e86-43e8-bcd5-544387bda53a.png#averageHue=%23f1f0f0&clientId=udab92dd4-9bf0-4&from=paste&height=234&id=u12dc9f39&originHeight=292&originWidth=1087&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=22214&status=done&style=none&taskId=u98a1c5ff-343c-4f09-b550-829173c3a82&title=&width=869.6)<br />Redis的hash之所以这样设计，是因为当ziplist变得很⼤的时候，它有如下几个缺点：

- 每次插⼊或修改引发的remalloc操作会有更⼤的概率造成内存拷贝，从而降低性能。
- ⼀旦发生内存拷贝，内存拷贝的成本也相应增加，因为要拷贝更⼤的⼀块数据。
- 当ziplist数据项过多的时候，在它上⾯查找指定的数据项就会性能变得很低，因为ziplist上的查找需要进行遍历。

总之，ziplist本来就设计为各个数据项挨在⼀起组成连续的内存空间，这种结构并不擅长做修改操作。⼀旦数据发⽣改动，就会引发内存remalloc，可能导致内存拷贝。

因此，Hash底层采用的编码与Zset也基本一致，只需要把排序有关的SkipList去掉即可：

<a name="adb0066c"></a>
## 2、原理篇-Redis网络模型

<a name="29250454"></a>
### 2.1 用户空间和内核态空间
进程的寻址空间划分成两部分：**内核空间、用户空间**

什么是寻址空间呢？我们的应用程序也好，还是内核空间也好，都是没有办法直接去物理内存的，而是通过分配一些虚拟内存映射到物理内存中，我们的内核和应用程序去访问虚拟内存的时候，就需要一个虚拟地址，这个地址是一个无符号的整数，比如一个32位的操作系统，他的带宽就是32，他的虚拟地址就是2的32次方，也就是说他寻址的范围就是0~2的32次方， 这片寻址空间对应的就是2的32个字节，就是4GB，这个4GB，会有3个GB分给用户空间，会有1GB给内核系统

在linux中，他们权限分成两个等级，0和3，用户空间只能执行受限的命令（Rank3），而且不能直接调用系统资源，必须通过内核提供的接口来访问内核空间可以执行特权命令（Rank0），调用一切系统资源，所以一般情况下，用户的操作是运行在用户空间，而内核运行的数据是在内核空间的，而有的情况下，一个应用程序需要去调用一些特权资源，去调用一些内核空间的操作，所以此时他俩需要在用户态和内核态之间进行切换。

比如：<br />Linux系统为了提高IO效率，会在用户空间和内核空间都加入缓冲区：<br />写数据时，要把用户缓冲数据拷贝到内核缓冲区，然后写入设备<br />读数据时，要从设备读取数据到内核缓冲区，然后拷贝到用户缓冲区

针对这个操作：我们的用户在写读数据时，会去向内核态申请，想要读取内核的数据，而内核数据要去等待驱动程序从硬件上读取数据，当从磁盘上加载到数据之后，内核会将数据写入到内核的缓冲区中，然后再将数据拷贝到用户态的buffer中，然后再返回给应用程序，整体而言，速度慢，就是这个原因，为了加速，我们希望read也好，还是wait for data也最好都不要等待，或者时间尽量的短。<br />在《UNIX网络编程》一书中，总结归纳了5种IO模型：

- 阻塞IO（Blocking IO）
- 非阻塞IO（Nonblocking IO）
- IO多路复用（IO Multiplexing）
- 信号驱动IO（Signal Driven IO）
- 异步IO（Asynchronous IO）
<a name="fd79c901"></a>
### 2.2.网络模型-阻塞IO
应用程序想要去读取数据，他是无法直接去读取磁盘数据的，他需要先到内核里边去等待内核操作硬件拿到数据，这个过程就是1，是需要等待的，等到内核从磁盘上把数据加载出来之后，再把这个数据写给用户的缓存区，这个过程是2，如果是阻塞IO，那么整个过程中，用户从发起读请求开始，一直到读取到数据，都是一个阻塞状态。<br />具体流程如下图：<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702370305733-37f6b3a1-65f0-49a3-b2cf-2cfa8b301b66.png#averageHue=%23e5eed6&clientId=udab92dd4-9bf0-4&from=paste&height=254&id=u88538f37&originHeight=317&originWidth=673&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=88890&status=done&style=none&taskId=u9d1a2ae0-ea2b-4117-92cf-ade9054883e&title=&width=538.4)<br />用户去读取数据时，会去先发起recvform一个命令，去尝试从内核上加载数据，如果内核没有数据，那么用户就会等待，此时内核会去从硬件上读取数据，内核读取数据之后，会把数据拷贝到用户态，并且返回ok，整个过程，都是阻塞等待的，这就是阻塞IO。阻塞IO就是**两个阶段都必须阻塞等待**：<br />**阶段一：**

- 用户进程尝试读取数据（比如网卡数据）
- 此时数据尚未到达，内核需要等待数据
- 此时用户进程也处于阻塞状态

阶段二：

- 数据到达并拷贝到内核缓冲区，代表已就绪
- 将内核数据拷贝到用户缓冲区
- 拷贝过程中，用户进程依然阻塞等待
- 拷贝完成，用户进程解除阻塞，处理数据

![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702370434117-766e64dd-8c1c-40d1-9937-bf45f6718c67.png#clientId=udab92dd4-9bf0-4&from=paste&height=410&id=ue7a5deed&originHeight=513&originWidth=1061&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=80823&status=done&style=none&taskId=ub818d79a-f869-4d47-9f92-279907ba2ec&title=&width=848.8)
<a name="3e7c12a2"></a>
### 2.3 网络模型-非阻塞IO
非阻塞IO的recvfrom操作会立即返回结果而不是阻塞用户进程。<br />阶段一：

- 用户进程尝试读取数据（比如网卡数据）
- 此时数据尚未到达，内核需要等待数据
- **返回异常给用户进程**
- **用户进程拿到error后，再次尝试读取**
- **循环往复，直到数据就绪**

阶段二：

- 将内核数据拷贝到用户缓冲区
- 拷贝过程中，用户进程依然阻塞等待
- 拷贝完成，用户进程解除阻塞，处理数据
- 可以看到，非阻塞IO模型中，用户进程在**第一个阶段是非阻塞**，**第二个阶段是阻塞状态**。虽然是非阻塞，但性能并没有得到提高。而且忙等机制会导致**CPU空转，CPU使用率暴增**。

![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702370514397-c2977e88-0a6a-488c-a3f8-8b0f3896e5cb.png#clientId=udab92dd4-9bf0-4&from=paste&height=414&id=uead1fb8d&originHeight=518&originWidth=1031&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=80442&status=done&style=none&taskId=uf167bc78-a792-4cc9-99cf-aa50e5fa700&title=&width=824.8)
<a name="cf964268"></a>
### 2.4 网络模型-IO多路复用
参考[https://zhuanlan.zhihu.com/p/367591714](https://zhuanlan.zhihu.com/p/367591714)<br />无论是阻塞IO还是非阻塞IO，用户应用在一阶段都需要调用recvfrom来获取数据，差别在于无数据时的处理方案：<br />如果调用recvfrom时，恰好没有数据，阻塞IO会使CPU阻塞，非阻塞IO使CPU空转，都不能充分发挥CPU的作用。<br />如果调用recvfrom时，恰好有数据，则用户进程可以直接进入第二阶段，读取并处理数据。<br />而在单线程情况下，只能依次处理IO事件，如果正在处理的IO事件恰好未就绪（数据不可读或不可写），线程就会被阻塞，所有IO事件都必须等待，性能自然会很差。

就比如服务员给顾客点餐，**分两步**：

- 顾客思考要吃什么（等待数据就绪）
- 顾客想好了，开始点餐（读取数据）

要提高效率有几种办法？<br />方案一：增加更多服务员（多线程）<br />方案二：不排队，谁想好了吃什么（数据就绪了），服务员就给谁点餐（**用户应用就去读取数据**）

那么问题来了：用户进程如何知道内核中数据是否就绪呢？<br />这个问题的解决依赖于提出的**文件描述符（File Descriptor）**：简称FD，是一个从0 开始的无符号整数，用来关联Linux中的一个文件。在Linux中，一切皆文件，例如常规文件、视频、硬件设备等，当然也包括网络套接字（Socket）。<br />通过FD，我们的网络模型可以**利用一个线程监听多个FD**，并在某个FD可读、可写时得到通知，从而避免无效的等待，充分利用CPU资源。<br />阶段一：

- 用户进程调用select，指定要监听的FD集合
- 核监听FD对应的多个socket
- 任意一个或多个socket数据就绪则返回readable
- 此过程中用户进程阻塞

阶段二：

- 用户进程找到就绪的socket
- 依次调用recvfrom读取数据
- 内核将数据拷贝到用户空间
- 用户进程处理数据

当用户去读取数据的时候，不再去直接调用recvfrom了，而是调用select的函数，select函数会将需要监听的数据交给内核，由内核去检查这些数据是否就绪了，如果说这个数据就绪了，就会通知应用程序数据就绪，然后来读取数据，再从内核中把数据拷贝给用户态，完成数据处理，如果N多个FD一个都没处理完，此时就进行等待。

用IO复用模式，可以确保去读数据的时候，数据是一定存在的，他的效率比原来的阻塞IO和非阻塞IO性能都要高<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702370777144-3c82b982-8031-4648-b3e1-d04f535edae1.png#averageHue=%23f7f7f7&clientId=udab92dd4-9bf0-4&from=paste&height=397&id=ub016bdd9&originHeight=496&originWidth=1014&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=95824&status=done&style=none&taskId=u802c87bf-be2e-4dd3-919c-11139dcfc6f&title=&width=811.2)<br />IO多路复用是利用单个线程来同时监听多个FD，并在某个FD可读、可写时得到通知，从而避免无效的等待，充分利用CPU资源。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的。不过监听FD的方式、通知的方式又有多种实现，常见的有：

- select
- poll
- epoll

其中select和poll相当于是当被监听的数据准备好之后，他会把你监听的FD整个数据都发给你，你需要到整个FD中去找，哪些是处理好了的，需要通过遍历的方式，所以性能也并不是那么好

而epoll，则相当于内核准备好了之后，他会把准备好的数据，直接发给你，咱们就省去了遍历的动作。
<a name="f34f9474"></a>
### 2.5 网络模型-IO多路复用-select方式
select是Linux最早是由的I/O多路复用技术：<br />简单说，就是我们把**需要处理的数据封装成FD**，然后在用户态时创建一个fd的集合（这个集合的大小是要监听的那个FD的最大值+1，但是大小整体是有限制的 ），这个集合的长度大小是有限制的，同时在这个集合中，标明出来我们要控制哪些数据，

比如要监听的数据，是1,2,5三个数据，此时会执行select函数，然后将**整个fd发给内核态**，内核态会去遍历用户态传递过来的数据，如果发现这里边都数据都没有就绪，就休眠，直到有数据准备好时，就会被唤醒，唤醒之后，再次遍历一遍，看看谁准备好了，然后再将处理掉没有准备好的数据，最后再**将这个FD集合写回到用户态中去**，此时用户态就知道了，奥，有人准备好了，但是对于用户态而言，并不知道谁处理好了，所以**用户态也需要去进行遍历**，然后找到对应准备好数据的节点，再去发起读请求，我们会发现，这种模式下他虽然比阻塞IO和非阻塞IO好，但是依然有些**麻烦的事情， 比如说频繁的传递fd集合，频繁的去遍历FD等问题**<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702371074790-72804cda-d1e7-46d0-bf51-75d0a2476e4d.png#averageHue=%23e7efe3&clientId=udab92dd4-9bf0-4&from=paste&height=510&id=u1401d7a8&originHeight=637&originWidth=1575&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=383966&status=done&style=none&taskId=u66d3b8b7-899b-4bab-b2b5-fbdb6ee6562&title=&width=1260)<br />![select.gif](https://cdn.nlark.com/yuque/0/2023/gif/40745172/1702372104121-db0105f6-f8fa-42f4-b3e5-5ac946e5c0c6.gif#averageHue=%23d3d4ca&clientId=udab92dd4-9bf0-4&from=paste&height=320&id=u35251abc&originHeight=400&originWidth=550&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=714304&status=done&style=none&taskId=u597e0892-62a6-4834-9602-fa9c83a5f26&title=&width=440)

<a name="ac8d619e"></a>
### 2.6 网络模型-IO多路复用模型-poll模式
poll模式对select模式做了简单改进，但性能提升不明显：<br />IO流程：

- 创建pollfd数组，向其中添加关注的fd信息，数组大小自定义
- 调用poll函数，将pollfd数组拷贝到内核空间，转链表存储，无上限
- 内核遍历fd，判断是否就绪
- 数据就绪或超时后，拷贝pollfd数组到用户空间，返回就绪fd数量n
- 用户进程判断n是否大于0,大于0则遍历pollfd数组，找到就绪的fd

**与select对比：**

- select模式中的fd_set大小固定为1024，而pollfd在内核中采用链表，理论上**无上限**
- 监听FD越多，每次遍历消耗时间也越久，性能反而会下降

![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702371233198-a4198203-07b2-4c39-a92c-d1ade702f463.png#clientId=udab92dd4-9bf0-4&from=paste&height=433&id=ucce34dde&originHeight=541&originWidth=731&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=206620&status=done&style=none&taskId=u67d3511d-9714-4b26-b4d1-0307a14dd08&title=&width=584.8)<br />![](.%5C%E5%8E%9F%E7%90%86%E7%AF%87.assets%5C1653900721427.png#id=ihvHi&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
<a name="3e62f75c"></a>
### 2.7 网络模型-IO多路复用模型-epoll函数
epoll模式是对select和poll的改进，它提供了三个函数：<br />第一个是：eventpoll的函数，他内部包含两个东西<br />一个是：<br />1、红黑树-> 记录的事要监听的FD<br />2、一个是链表->一个链表，记录的是就绪的FD<br />紧接着调用epoll_ctl操作，将要监听的数据添加到红黑树上去，并且给每个fd设置一个监听（回调）函数，这个函数会在fd数据就绪时触发，就是准备好了，现在就把fd把数据添加到list_head中去<br />3、调用epoll_wait函数<br />就去等待，在用户态创建一个空的events数组，当就绪之后，我们的回调函数会把数据添加到list_head中去，当调用这个函数的时候，会去检查list_head，当然这个过程需要参考配置的等待时间，可以等一定时间，也可以一直等， 如果在此过程中，检查到了list_head中有数据会将数据添加到链表中，此时将数据放入到events数组中，并且返回对应的操作的数量，用户态的此时收到响应后，从events中拿到对应准备好的数据的节点，再去调用方法去拿数据。

小总结：<br />select模式存在的三个问题：

- 能监听的FD最大不超过1024
- 每次select都需要把所有要监听的FD都拷贝到内核空间
- 每次都要遍历所有FD来判断就绪状态

poll模式的问题：

- poll利用链表解决了select中监听FD上限的问题，但依然要遍历所有FD，如果监听较多，性能会下降

epoll模式中如何解决这些问题的？

- 基于epoll实例中的红黑树保存要监听的FD，理论上无上限，而且增删改查效率都非常高
- 每个FD只需要执行一次epoll_ctl添加到红黑树，以后每次epol_wait无需传递任何参数，**无需重复拷贝FD**到内核空间
- 利用ep_poll_callback机制来监听FD状态，**无需遍历所有FD**，因此性能不会随监听的FD数量增多而下降

![epoll.gif](https://cdn.nlark.com/yuque/0/2023/gif/40745172/1702372396834-ba1e8291-968d-47e0-9f71-f0a141f6139f.gif#averageHue=%23d3d4ca&clientId=udab92dd4-9bf0-4&from=paste&height=320&id=u38c95817&originHeight=400&originWidth=550&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=550346&status=done&style=none&taskId=udd5c62d5-4c3b-46d7-96b9-6d570f8d641&title=&width=440)
<a name="ad6c5f19"></a>
### 2.8、网络模型-epoll中的ET和LT

如何理解Epoll中的LT和ET模式，底层实现又是怎么样的？ [https://www.zhihu.com/question/403893498/answer/2258283710](https://www.zhihu.com/question/403893498/answer/2258283710)

当FD有数据可读时，我们调用epoll_wait（或者select、poll）可以得到通知。但是事件通知的模式有两种：

- LevelTriggered：简称LT，也叫做水平触发。只要某个FD中有数据可读，每次调用epoll_wait都会得到通知，即持续通知直到处理事件完毕。
- EdgeTriggered：简称ET，也叫做边沿触发。只有在某个FD有状态变化时，调用epoll_wait才会被通知，即只通知一次，不管事件是否处理完毕。

举个栗子：

- 假设一个客户端socket对应的FD已经注册到了epoll实例中
- 客户端socket发送了2kb的数据
- 服务端调用epoll_wait，得到通知说FD就绪
- 服务端从FD读取了1kb数据回到步骤3（再次调用epoll_wait，形成循环）

结论

如果我们采用LT模式，因为FD中仍有1kb数据，则第⑤步依然会返回结果，并且得到通知<br />如果我们采用ET模式，因为第③步已经消费了FD可读事件，第⑤步FD状态没有变化，因此epoll_wait不会返回，数据无法读取，客户端响应超时。

<a name="666970a1"></a>
### 2.9 网络模型-基于epoll的服务器端流程

服务器启动以后，服务端会去调用epoll_create，创建一个epoll实例，epoll实例中包含两个数据<br />1、红黑树（为空）：rb_root 用来去记录需要被监听的FD<br />2、链表（为空）：list_head，用来存放已经就绪的FD

创建好了之后，会去调用epoll_ctl函数，此函数会会将需要监听的数据添加到rb_root中去，并且对当前这些存在于红黑树的节点设置回调函数，当这些被监听的数据一旦准备完成，就会被调用，而调用的结果就是将红黑树的fd添加到list_head中去(但是此时并没有完成)

3、当第二步完成后，就会调用epoll_wait函数，这个函数会去校验是否有数据准备完毕（因为数据一旦准备就绪，就会被回调函数添加到list_head中），在等待了一段时间后(可以进行配置)，如果等够了超时时间，则返回没有数据，如果有，则进一步判断当前是什么事件，如果是建立连接时间，则调用accept() 接受客户端socket，拿到建立连接的socket，然后建立起来连接，如果是其他事件，则把数据进行写出<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702379331609-9029e290-21be-4dbb-94de-7103b6af8419.png#averageHue=%23e0e9de&clientId=udab92dd4-9bf0-4&from=paste&height=511&id=u444b49ee&originHeight=639&originWidth=1528&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=207920&status=done&style=none&taskId=ud7063606-f3e7-4b31-8714-28ae535b2ec&title=&width=1222.4)<br />![](.%5C%E5%8E%9F%E7%90%86%E7%AF%87.assets%5C1653902845082.png#id=KFvRe&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
<a name="52bbf270"></a>
### 3.0 、网络模型-信号驱动

信号驱动IO是与内核建立SIGIO的信号关联并设置回调，当内核有FD就绪时，会发出SIGIO信号通知用户，期间用户应用可以执行其它业务，无需阻塞等待。<br />阶段一：

- 用户进程调用sigaction，注册信号处理函数
- 内核返回成功，开始监听FD
- 用户进程不阻塞等待，可以执行其它业务
- 当内核数据就绪后，回调用户进程的SIGIO处理函数

阶段二：

- 收到SIGIO回调信号
- 调用recvfrom，读取
- 内核将数据拷贝到用户空间
- 用户进程处理数据

![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702379463130-25d74b4a-d32f-4b4f-aebd-e854c21bd019.png#averageHue=%23f6f6f6&clientId=udab92dd4-9bf0-4&from=paste&height=421&id=uc2ed9200&originHeight=526&originWidth=937&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=122033&status=done&style=none&taskId=u59900219-e109-4518-b289-06925d1c0ee&title=&width=749.6)<br />当有大量IO操作时，信号较多，SIGIO处理函数不能及时处理可能导致信号队列溢出，而且内核空间与用户空间的频繁信号交互性能也较低。

<a name="d95b3e79"></a>
#### 3.0.1 异步IO

- 在IO模型里面如果请求方从发起请求到数据最后完成的这一段过程中都需要自己参与，那么这种我们称为同步；
- 如果应用发送完指令后就不再参与过程了，只需要等待最终完成结果的通知，那么这就属于异步。

这种方式，不仅仅是用户态在试图读取数据后，不阻塞，而且当内核的数据准备完成后，也不会阻塞<br />他会由内核将所有数据处理完成后，由内核将数据写入到用户态中，然后才算完成，所以性能极高，不会有任何阻塞，全部都由内核完成，可以看到，异步IO模型中，用户进程在两个阶段都是非阻塞状态。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702379669424-cd6aaae6-6a5e-4b61-b3cd-d64c1f234d93.png#averageHue=%23f9f9f9&clientId=udab92dd4-9bf0-4&from=paste&height=413&id=u8ad94e21&originHeight=516&originWidth=1094&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=80387&status=done&style=none&taskId=u6786c95c-a92e-48d9-9e96-336a8e9b740&title=&width=875.2)
<a name="5fa292df"></a>
#### 3.0.2 对比
![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702379751325-905ac8ad-ea32-41c2-a37b-38fc0f2d2250.png#averageHue=%23ededed&clientId=udab92dd4-9bf0-4&from=paste&height=505&id=ub3057925&originHeight=631&originWidth=989&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=221728&status=done&style=none&taskId=u62613d48-4343-4b53-8906-e91cdbb3070&title=&width=791.2)

<a name="48bcdde3"></a>
### 3.1 、网络模型-Redis是单线程的吗？为什么使用单线程

**Redis到底是单线程还是多线程？**

- 如果仅仅聊Redis的核心业务部分（命令处理），答案是单线程
- 如果是聊整个Redis，那么答案就是多线程

在Redis版本迭代过程中，在两个重要的时间节点上引入了多线程的支持：

- Redis v4.0：引入多线程异步处理一些耗时较旧的任务，例如异步删除命令unlink
- Redis v6.0：在核心网络模型中引入 多线程，进一步提高对于多核CPU的利用率

因此，对于Redis的核心网络模型，在Redis 6.0之前确实都是单线程。是利用epoll（Linux系统）这样的IO多路复用技术在事件循环中不断处理客户端情况。

**为什么Redis要选择单线程？**

- 抛开持久化不谈，Redis是**纯内存操作**，执行速度非常快，它的性能瓶颈是网络延迟而不是执行速度，因此多线程并不会带来巨大的性能提升。
- 多线程会导致过多的**上下文切换**，带来不必要的开销
- 引入多线程会面临**线程安全问题**，必然要引入线程锁这样的安全手段，实现复杂度增高，而且性能也会大打折扣

<a name="5e2fe412"></a>
### 3.2 、Redis的单线程模型-Redis单线程和多线程网络模型变更
![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702380112220-b3bbabdd-7959-4a18-af89-a2c2564b521b.png#averageHue=%23f1efed&clientId=u66d5f54d-10f9-4&from=paste&height=506&id=u94f242e7&originHeight=633&originWidth=1557&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=498223&status=done&style=none&taskId=ue7cba497-08b3-4abb-8a06-19385348951&title=&width=1245.6)<br />当我们的客户端想要去连接我们服务器，会去先到IO多路复用模型去进行排队，会有一个连接应答处理器，他会去接受读请求，然后又把读请求注册到具体模型中去，此时这些建立起来的连接，如果是客户端请求处理器去进行执行命令时，他会去把数据读取出来，然后把数据放入到client中， clinet去解析当前的命令转化为redis认识的命令，接下来就开始处理这些命令，从redis中的command中找到这些命令，然后就真正的去操作对应的数据了，当数据操作完成后，会去找到命令回复处理器，再由他将数据写出。<br />**通信流程**<br />1、首先在redis启动初始化的时候，redis会先将事件处理器中的**连接应答处理器**和**AE_READABLE事件关联**起来;<br />2、如果客户端向redis发起**连接**，会产生**AE_READABLE**事件(步骤A)，产生该事件后会被IO多路复用程序监听到(步骤B)，然后IO多路复用程序会把**监听到的socket信息放入到队列中(步骤C)**，事件分配器每次从队列中取出一个socket(步骤D)，然后事件分派器把**socket给对应的事件处理器**(步骤E)。由于连接应答处理器和AE_READABLE事件在redis初始化的时候已经关联起来，所以由连接应答处理器来处理跟客户端建立连接，然后通过ServerSocket创建一个与客户端一对一对应的socket，如叫socket01，同时将这个socket01的**AE_READABLE事件和命令请求处理器关联**起来。<br />![](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702381023060-823b02bf-dcf6-455b-aa9f-0791d86563f5.png#averageHue=%23f7f6f6&clientId=u66d5f54d-10f9-4&from=paste&id=u3ee9aa5c&originHeight=449&originWidth=1365&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u974b2d9f-e187-4c60-9aba-8b1c5bf69d9&title=)<br />4、当客户端向redis发生**请求时(读、写操作)**，首先就会在对应的socket如socket01上会产生**AE_READABLE事件**(步骤A)，产生该事件后会被IO多路复用程序监听到(步骤B)，然后IO多路复用程序会把监听到的socket信息放入到队列中(步骤C)，事件分配器**每次从队列中取出一个socket(步骤D)**，然后事件分派器把socket给对应的事件处理器(步骤E)。由于命令处理器和socket01的AE_READABLE事件关联起来了，然后对应的命令请求处理器来处理。这个命令请求处理器会从事件分配器传递过来的socket01上读取相关的数据，如何执行相应的读写处理。操作执行完之后，redis就会将**准备好相应的响应数据**(如你在redis客户端输入 set a 123回车时会看到响应ok)，并**将socket01的AE_WRITABLE事件和命令回复处理器关联**起来。<br />![](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702381022986-177686bc-9f4f-4bb8-89fb-7cab9e1a61d3.png#averageHue=%23f7f6f6&clientId=u66d5f54d-10f9-4&from=paste&id=u59456bca&originHeight=476&originWidth=1397&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=uc787ef3e-332a-4443-9834-84624ba7716&title=)<br />5、当客户端会查询redis是否完成相应的操作，就会在socket01上产生一个AE_WRITABLE事件，会由对应的命令回复处理器来处理，就是将准备好的相应数据写入socket01(由于socket连接是双向的),返回给客户端，如读操作，客户端会显示ok。<br />![](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702381022960-308bb0e7-5588-4229-a282-e5b53f4bd378.png#averageHue=%23f8f7f7&clientId=u66d5f54d-10f9-4&from=paste&id=u883b9097&originHeight=546&originWidth=1366&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=ue45dcc0e-45c5-48b0-938e-905cdf51b9a&title=)<br />6、如果**命令回复处理器执行完成后，就会删除这个socket01的AE_WRITABLE事件和命令回复处理器的关联**。<br />7、这样客户端就和redis进行了一次通信。由于**连接应答处理器执行一次就够**了，如果客户端在次进行操作就会由命令请求处理器来处理，反复执行。
<a name="4cee9975"></a>
## 3、Redis通信协议-RESP协议

Redis是一个CS架构的软件，通信一般分两步（不包括pipeline和PubSub）：<br />客户端（client）向服务端（server）发送一条命令<br />服务端解析并执行命令，返回响应结果给客户端

因此客户端发送命令的格式、服务端响应结果的格式必须有一个规范，这个规范就是通信协议。<br />而在Redis中采用的是RESP（Redis Serialization Protocol）协议：<br />Redis 1.2版本引入了RESP协议<br />Redis 2.0版本中成为与Redis服务端通信的标准，称为RESP2<br />Redis 6.0版本中，从RESP2升级到了RESP3协议，增加了更多数据类型并且支持6.0的新特性--客户端缓存<br />但目前，默认使用的依然是RESP2协议，也是我们要学习的协议版本（以下简称RESP）。

在RESP中，通过首字节的字符来区分不同数据类型，常用的数据类型包括5种：<br />**单行字符串**：首字节是 ‘**_+_**’ ，后面跟上单行字符串，以CRLF（ "\r\n" ）结尾。例如返回"OK"： "+OK\r\n"<br />**错误（Errors**）：首字节是 ‘**-**’ ，与单行字符串格式一样，只是字符串是异常信息，例如："-Error message\r\n"<br />**数值**：首字节是 ‘**:**’ ，后面跟上数字格式的字符串，以CRLF结尾。例如：":10\r\n"<br />**多行字符串**：首字节是 ‘**$**’ ，表示二进制安全的字符串，最大支持512MB：<br />如果大小为0，则代表空字符串："$0\r\n\r\n"<br />如果大小为-1，则代表不存在："$-1\r\n"<br />**数组**：首字节是 ‘*’，后面跟上数组元素个数，再跟上元素，元素数据类型不限:

![](.%5C%E5%8E%9F%E7%90%86%E7%AF%87.assets%5C1653982993020.png#id=txJ93&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)

<a name="9906c113"></a>
### 3.1、Redis通信协议-基于Socket自定义Redis的客户端

Redis支持TCP通信，因此我们可以使用Socket来模拟客户端，与Redis服务端建立连接：

```java
public class Main {

    static Socket s;
    static PrintWriter writer;
    static BufferedReader reader;

    public static void main(String[] args) {
        try {
            // 1.建立连接
            String host = "192.168.150.101";
            int port = 6379;
            s = new Socket(host, port);
            // 2.获取输出流、输入流
            writer = new PrintWriter(new OutputStreamWriter(s.getOutputStream(), StandardCharsets.UTF_8));
            reader = new BufferedReader(new InputStreamReader(s.getInputStream(), StandardCharsets.UTF_8));

            // 3.发出请求
            // 3.1.获取授权 auth 123321
            sendRequest("auth", "123321");
            Object obj = handleResponse();
            System.out.println("obj = " + obj);

            // 3.2.set name 虎哥
            sendRequest("set", "name", "虎哥");
            // 4.解析响应
            obj = handleResponse();
            System.out.println("obj = " + obj);

            // 3.2.set name 虎哥
            sendRequest("get", "name");
            // 4.解析响应
            obj = handleResponse();
            System.out.println("obj = " + obj);

            // 3.2.set name 虎哥
            sendRequest("mget", "name", "num", "msg");
            // 4.解析响应
            obj = handleResponse();
            System.out.println("obj = " + obj);
        } catch (IOException e) {
            e.printStackTrace();
        } finally {
            // 5.释放连接
            try {
                if (reader != null) reader.close();
                if (writer != null) writer.close();
                if (s != null) s.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
    }

    private static Object handleResponse() throws IOException {
        // 读取首字节
        int prefix = reader.read();
        // 判断数据类型标示
        switch (prefix) {
            case '+': // 单行字符串，直接读一行
                return reader.readLine();
            case '-': // 异常，也读一行
                throw new RuntimeException(reader.readLine());
            case ':': // 数字
                return Long.parseLong(reader.readLine());
            case '$': // 多行字符串
                // 先读长度
                int len = Integer.parseInt(reader.readLine());
                if (len == -1) {
                    return null;
                }
                if (len == 0) {
                    return "";
                }
                // 再读数据,读len个字节。我们假设没有特殊字符，所以读一行（简化）
                return reader.readLine();
            case '*':
                return readBulkString();
            default:
                throw new RuntimeException("错误的数据格式！");
        }
    }

    private static Object readBulkString() throws IOException {
        // 获取数组大小
        int len = Integer.parseInt(reader.readLine());
        if (len <= 0) {
            return null;
        }
        // 定义集合，接收多个元素
        List<Object> list = new ArrayList<>(len);
        // 遍历，依次读取每个元素
        for (int i = 0; i < len; i++) {
            list.add(handleResponse());
        }
        return list;
    }

    // set name 虎哥
    private static void sendRequest(String ... args) {
        writer.println("*" + args.length);
        for (String arg : args) {
            writer.println("$" + arg.getBytes(StandardCharsets.UTF_8).length);
            writer.println(arg);
        }
        writer.flush();
    }
}
```

<a name="KoPlc"></a>
## 3.2、Redis内存回收-过期key处理

Redis之所以性能强，最主要的原因就是基于内存存储。然而单节点的Redis其内存大小不宜过大，会影响持久化或主从同步性能。<br />我们可以通过修改配置文件来设置Redis的最大内存：<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702381445606-b04320d2-87be-4189-b4ea-dc2caf8a4884.png#averageHue=%23f4f9f0&clientId=u66d5f54d-10f9-4&from=paste&height=76&id=u46e44955&originHeight=95&originWidth=606&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=5425&status=done&style=none&taskId=u19bafc44-5e32-470d-ab77-2acced6e40f&title=&width=484.8)<br />当内存使用达到上限时，就无法存储更多数据了。为了解决这个问题，Redis提供了一些策略实现内存回收：<br />**内存过期策略**<br />可以通过expire命令给Redis的key设置TTL（存活时间），可以发现，当key的TTL到期以后，再次访问name返回的是nil，说明这个key已经不存在了，对应的内存也得到释放。从而起到内存回收的目的。

Redis本身是一个典型的key-value内存存储数据库，因此所有的key、value都保存在之前学习过的Dict结构中。不过在其**database结构体中，有两个Dict：一个用来记录key-value；另一个用来记录key-TTL。**<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702381544749-d2bf3e5d-f202-43f3-89c3-1d868efa323e.png#averageHue=%23f2f8ee&clientId=u66d5f54d-10f9-4&from=paste&height=286&id=ub73aad3f&originHeight=358&originWidth=965&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=48973&status=done&style=none&taskId=u03b7e985-5610-4647-bd6c-1326b65bb27&title=&width=772)<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702381575575-93c86f5e-8645-400f-9613-58568713c22e.png#averageHue=%23ececec&clientId=u66d5f54d-10f9-4&from=paste&height=565&id=u0585642c&originHeight=706&originWidth=1449&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=55768&status=done&style=none&taskId=u3434b263-649c-4076-85b3-93b8d8ba043&title=&width=1159.2)<br />这里有两个问题需要我们思考：<br />Redis是如何知道一个key是否过期呢？<br />利用两个Dict分别记录key-value对及key-ttl对，是不是TTL到期就立即删除了呢？

**惰性删除**<br />惰性删除：顾明思议并不是在TTL到期后就立刻删除，而是在**访问一个key的时候**，检查该key的存活时间，如果已经过期才执行删除。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702381629387-b483be31-3da5-4949-9d9e-c62d19da56d1.png#averageHue=%23f5f8ee&clientId=u66d5f54d-10f9-4&from=paste&height=232&id=u687c5b3e&originHeight=290&originWidth=1042&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=44881&status=done&style=none&taskId=uc93d8edf-3471-47b8-963e-7c26a456cba&title=&width=833.6)

**周期删除**

周期删除：顾明思议是通过一个**定时任务，周期性的抽样**部分过期的key，然后执行删除。执行周期有两种：<br />Redis服务初始化函数initServer()中设置定时任务，按照server.hz的频率来执行过期key清理，模式为**SLOW**<br />Redis的每个事件循环前会调用beforeSleep()函数，执行过期key清理，模式为**FAST**

**SLOW模式规则：**

- 执行频率受server.hz影响，默认为10，即**每秒执行10次，每个执行周期100ms**。
- 执行清理耗时不超过一次执行周期的25%.默认slow模式耗时不超过25ms
- 逐个遍历db，逐个**遍历db中的bucket，抽取20个key判断是否过期**
- 如果没达到时间上限（25ms）并且**过期key比例大于25%**，再进行一次抽样，否则结束

**FAST模式规则（过期key比例小于25%不执行 ）：**

- 执行频率受beforeSleep()调用频率影响，但两次FAST模式间隔不低于2ms
- 执行清理耗时不超过1ms
- 逐个遍历db，逐个遍历db中的bucket，抽取20个key判断是否过期<br />如果没达到时间上限（1ms）并且过期key比例大于25%，再进行一次抽样，否则结束

小总结：<br />RedisKey的TTL记录方式：在RedisDB中通过一个Dict记录每个Key的TTL时间

过期key的删除策略：

- 惰性清理：每次查找key时判断是否过期，如果过期则删除
- 定期清理：定期抽样部分key，判断是否过期，如果过期则删除。<br />定期清理的两种模式：
   - SLOW模式执行频率默认为10，每次不超过25ms
   - FAST模式执行频率不固定，但两次间隔不低于2ms，每次耗时不超过1ms

<a name="fgAMS"></a>
## 3.3 Redis内存回收-内存淘汰策略

内存淘汰：就是当Redis内存使用达到设置的上限时，主动挑选部分key删除以释放更多内存的流程。Redis会在处理客户端命令的方法processCommand()中尝试做内存淘汰

**淘汰策略**<br />Redis支持8种不同策略来选择要删除的key：

- noeviction： 不淘汰任何key，但是内存满时不允许写入新数据，默认就是这种策略。
- volatile-ttl： 对设置了TTL的key，比较key的剩余TTL值，TTL越小越先被淘汰
- allkeys-random：对全体key ，随机进行淘汰。也就是直接从db->dict中随机挑选
- volatile-random：对设置了TTL的key ，随机进行淘汰。也就是从db->expires中随机挑选。
- allkeys-lru： 对全体key，基于LRU算法进行淘汰
- volatile-lru： 对设置了TTL的key，基于LRU算法进行淘汰
- allkeys-lfu： 对全体key，基于LFU算法进行淘汰
- volatile-lfu： 对设置了TTL的key，基于LFI算法进行淘汰<br />比较容易混淆的有两个： 
   - LRU（Least Recently Used），最少最近使用。用**当前时间减去最后一次访问时间**，这个值越大则淘汰优先级越高。
   - LFU（Least Frequently Used），最少频率使用。会统计每个**key的访问频率**，值越小淘汰优先级越高。

LFU的访问次数之所以叫做逻辑访问次数，是因为并不是每次key被访问都计数，而是通过运算（因为只有低八位用来记录，最大255）：

- 生成0~1之间的随机数R
- 计算 (旧次数 * lfu_log_factor + 1)，记录为P
- 如果 R < P ，则计数器 + 1，且最大不超过255
- 访问次数会随时间衰减，距离上一次访问时间每隔 lfu_decay_time 分钟，计数器 -1

最后用一副图来描述当前的这个流程吧<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/40745172/1702382090129-20cf7b23-ff30-4106-bf76-c1eda52fe2ee.png#averageHue=%23f8f8f8&clientId=u66d5f54d-10f9-4&from=paste&height=629&id=ufb9ff867&originHeight=786&originWidth=1585&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=340201&status=done&style=none&taskId=uc27c90a5-d673-47e1-8a68-fd64ca93c32&title=&width=1268)
<a name="COTHq"></a>
## 4、Redis持久化策略
Redis有两种持久化策略：RDB、AOF
<a name="OXjrO"></a>
### 4.1、RDB持久化
RDB全称Redis Database Backup file（Redis数据备份文件），也被叫做Redis数据快照。简单来说就是把**内存中的所有数据都记录到磁盘中**。当Redis实例故障重启后，从磁盘读取快照文件，恢复数据。快照文件称为RDB文件，默认是保存在当前运行目录。
<a name="Wuxh5"></a>
#### 执行时机
RDB持久化会在以下四种情况下执行：

- 执行save命令
- 执行bgsave命令
- Redis停机时
- 触发RDB条件时
<a name="uVTYW"></a>
##### 1）save命令
执行下面的命令，可以立即执行一次RDB：<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/40745172/1704973417990-c8b4c90b-0260-4ba7-a66b-a36750a088ce.png#averageHue=%23042d49&clientId=u124f52f5-ffe3-4&from=paste&height=154&id=u116bc96a&originHeight=193&originWidth=1108&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=56673&status=done&style=none&taskId=u48b70da3-0afd-441d-b8c1-eccc19b8f80&title=&width=886.4)<br />**save命令会导致主进程执行RDB**，这个过程中其它所有命令都会被**阻塞**。只有在数据迁移时可能用到。
<a name="wMhIa"></a>
##### 2）bgsave命令
下面的命令可以异步执行RDB：<br />![image.png](https://cdn.nlark.com/yuque/0/2024/png/40745172/1704973458077-1d83afa2-2dc8-4997-849b-72e799d2573c.png#averageHue=%23042d48&clientId=u124f52f5-ffe3-4&from=paste&height=90&id=u157865ec&originHeight=112&originWidth=1157&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=19718&status=done&style=none&taskId=u972d83e7-25d7-4638-9ba7-c80af835b96&title=&width=925.6)<br />这个命令执行后会**开启独立进程完成RDB**，主进程可以持续处理用户请求，不受影响。
<a name="o0h8g"></a>
##### 3）停机时
Redis停机前会执行一次save命令，实现RDB持久化。
<a name="WMh1g"></a>
##### 4）触发RDB条件
Redis内部有触发RDB的机制，可以在**redis.conf**文件中找到，格式如下：
```properties
# 900秒内，如果至少有1个key被修改，则执行bgsave ， 如果是save "" 则表示禁用RDB
save 900 1  
save 300 10  
save 60 10000
```
RDB的其它配置也可以在redis.conf文件中设置
```properties
# 是否压缩 ,建议不开启，压缩也会消耗cpu，磁盘的话不值钱
rdbcompression yes

# RDB文件名称
dbfilename dump.rdb  

# 文件保存的路径目录
dir ./
```
<a name="S6eUk"></a>
#### RDB原理
bgsave开始时会fork主进程得到子进程，子进程共享主进程的内存数据。完成fork后读取内存数据并写入 RDB 文件。<br />_在 Linux 系统中，调用 fork() 时，会创建出一个新进程，称为子进程，子进程会拷贝父进程的 page table。如果进程占用的内存越大，进程的 page table 也会越大，那么 fork 也会占用更多的时间。如果 Redis 占用的内存很大，那么在 fork 子进程时，则会出现明显的停顿现象。_<br />fork采用的是**copy-on-write**技术：

- 当主进程执行读操作时，访问共享内存；
- 当主进程执行写操作时，则会拷贝一份数据，执行写操作。

![image.png](https://cdn.nlark.com/yuque/0/2024/png/40745172/1704973658370-f6e6f5a7-f048-4ecb-bbe4-a9c43c8c55ae.png#averageHue=%23f7efef&clientId=u124f52f5-ffe3-4&from=paste&height=438&id=ua5392f30&originHeight=547&originWidth=1514&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=82508&status=done&style=none&taskId=u9a3f9f4e-d87b-4da7-b24a-827f4f00435&title=&width=1211.2)
<a name="jJhPL"></a>
#### 小结
RDB方式bgsave的基本流程？

- fork主进程得到一个子进程，共享内存空间
- 子进程读取内存数据并写入新的RDB文件
- 用新RDB文件替换旧的RDB文件

RDB会在什么时候执行？save 60 1000代表什么含义？

- 默认是服务停止时
- 代表60秒内至少执行1000次修改则触发RDB

RDB优点？

- RDB 文件是是经过压缩的二进制文件，**占用空间很小**，它保存了 Redis 某个时间点的数据集，很适合用于做备份。
- RDB 非常适用于**灾难恢复**（disaster recovery）：它只有一个文件，并且内容都非常紧凑，可以（在加密后）将它传送到别的数据中心。
- RDB 可以**最大化 redis 的性能**。父进程在保存 RDB 文件时唯一要做的就是 fork 出一个子进程，然后这个子进程就会处理接下来的所有保存工作，父进程无须执行任何磁盘 I/O 操作。
- RDB 在**恢复大数据集**时的速度比 AOF 的恢复速度要快。

RDB的缺点？

- RDB执行间隔时间长，两次RDB之间写入**数据有丢失的风险**。通常可能设置至少5分钟才保存一次快照，这时如果 Redis 出现宕机等情况，则意味着最多可能丢失5分钟数据。
- fork子进程、压缩、写出RDB文件都比较**耗时**
- Linux fork 子进程采用的是 copy-on-write 的方式。在 Redis 执行 RDB 持久化期间，如果 client 写入数据很频繁，那么将增加 Redis 占用的内存，最坏情况下，内存的占用将达到原先的2倍。刚 fork 时，主进程和子进程共享内存，但是随着主进程需要处理写操作，主进程需要将修改的页面拷贝一份出来，然后进行修改。极端情况下，如果**所有的页面都被修改**，则此时的内存占用是原先的2倍。
<a name="RVcwb"></a>
### 4.2、AOF持久化
保存 Redis 服务器所执行的所有**写操作命令**来记录数据库状态，并在服务器启动时，通过重新执行这些命令来还原数据集。
<a name="s7odi"></a>
#### AOF功能实现原理
开启：AOF 持久化**默认是关闭**的，可以通过配置：appendonly yes 开启。<br />关闭：使用配置 appendonly no 可以关闭 AOF 持久化。<br />AOF 持久化功能的实现可以分为三个步骤：**命令追加、文件写入、文件同步**。

- 命令追加：当 AOF 持久化功能打开时，服务器在**执行完一个写命令之后**，会将**被执行的写命令追加到服务器状态的 aof 缓冲区**（`aof_buf`）的末尾。
- 文件写入（page cache）与文件同步（磁盘）：Linux 操作系统中为了提升性能，使用了页缓存（`page cache`）。当我们将 **aof_buf 的内容写到磁盘上时，此时数据并没有真正的落盘，而是在 page cache 中**，为了将 page cache 中的数据真正落盘，需要执行 fsync / fdatasync 命令来强制刷盘。这边的文件同步做的就是刷盘操作，或者叫文件刷盘可能更容易理解一些。

**flushAppendOnlyFile** 函数，该函数会根据服务器配置的 `**appendfsync**` 参数值，来决定是否将 aof_buf 缓冲区的内容写入和保存到 AOF 文件。<br />**appendfsync 参数有三个选项：**<br />1）**always**：每处理一个命令都将 aof_buf 缓冲区中的所有内容写入并同步到AOF 文件，即每个命令都刷盘。**也就是aof buf 的内容写入page cache的同时刷盘写到AOF文件**<br />2）**everysec**：将 aof_buf 缓冲区中的所有内容写入到 AOF 文件，如果上次同步 AOF 文件的时间距离现在超过一秒钟， 那么再次对 AOF 文件进行同步， 并且这个同步操作是异步的，由一个后台线程专门负责执行，即**每秒刷盘1次**。**也就是每次aof buf的变化都写入page cache中，每隔一秒将page cache中内容写入AOF文件**<br />3）**no**：将 aof_buf 缓冲区中的所有内容写入到 AOF 文件， 但并不对 AOF 文件进行同步， 何时同步由操作系统来决定。即不执行刷盘，让**操作系统自己执行刷盘**。**只将aof buf 的内容写入page cache中，不进行刷盘，具体刷盘由操作系统决定。**
<a name="cH3oz"></a>
#### 小结
AOF优点：

- **AOF 比 RDB可靠**。你可以设置不同的 fsync 策略：no、everysec 和 always。**默认是 everysec**，在这种配置下，redis 仍然可以保持良好的性能，并且就算发生故障停机，也**最多只会丢失一秒钟的数据**。
- AOF文件是一个**纯追加的日志文件**。即使日志因为某些原因而包含了未写入完整的命令（比如写入时磁盘已满，写入中途停机等等）， 我们也可以使用 redis-check-aof 工具也可以轻易地修复这种问题。
- 当 **AOF文件太大时，Redis 会自动在后台进行重写**：重写后的新 AOF 文件包含了恢复当前数据集所需的**最小命令集合**。整个重写是绝对安全，因为重写是在一个新的文件上进行，同时 Redis 会继续往旧的文件追加数据。当新文件重写完毕，Redis 会把新旧文件进行切换，然后开始把数据写到新文件上。用最少的命令实现同样的功能![image.png](https://cdn.nlark.com/yuque/0/2024/png/40745172/1704974740727-ecf7ce83-db11-4a42-ab8f-9485cf2a585c.png#averageHue=%23f9f8f8&clientId=u124f52f5-ffe3-4&from=paste&height=107&id=u2301afb1&originHeight=134&originWidth=970&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=15488&status=done&style=none&taskId=u89b79634-3035-408d-a34f-c26b76829b5&title=&width=776)
- AOF 文件有序地保存了对数据库执行的所有写入操作以 Redis 协议的格式保存， 因此** AOF 文件的内容非常容易被人读懂**， 对文件进行分析（parse）也很轻松。如果你**不小心执行了 FLUSHALL 命令**把所有数据刷掉了，但只要 AOF 文件没有被重写，那么只要停止服务器， **移除 AOF 文件末尾的 FLUSHALL 命令**， 并**重启 Redis **， 就可以将数据集恢复到 FLUSHALL 执行之前的状态。

AOF缺点：

- 对于相同的数据集，AOF 文件的大小一般会比 RDB **文件大**。
- 根据所**使用的 fsync 策略**，AOF 的速度可能会**比 RDB 慢**。通常 fsync 设置为每秒一次就能获得比较高的性能，而关闭 fsync 可以让 AOF 的速度和 RDB 一样快。
<a name="QizFu"></a>
### 4.3、混合持久化
<a name="Sp3uy"></a>
#### 实现原理
混合持久化只发生于** AOF 重写过程**。使用了混合持久化，**重写后的新 AOF 文件前半段是 RDB 格式的全量数据，后半段是 AOF 格式的增量数据**。<br />开启：混合持久化的配置参数为 `**aof-use-rdb-preamble yes**`，开启混合持久化，在 redis 4 刚引入时，默认是关闭混合持久化的，但是在 redis 5 中默认已经打开了。<br />关闭：使用`** aof-use-rdb-preamble no **`配置即可关闭混合持久化。<br />混合持久化本质是通过 AOF 后台重写（bgrewriteaof 命令）完成的，不同的是当开启混合持久化时，f**ork 出的子进程先将当前全量数据以 RDB 方式写入新的 AOF 文件**，然后再将 **AOF 重写缓冲区**（`**aof_rewrite_buf_blocks**`）的**增量命令**以 **AOF 方式**写入到文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。
<a name="GALZl"></a>
#### AOF重写存在的问题
AOF 后台重写使用子进程进行从写，解决了主进程阻塞的问题，但是仍然存在另一个问题：子进程在进行 AOF 重写期间，服务器**主进程还需要继续处理命令请求**，**新的命令可能会对现有的数据库状态进行修改**，从而使得**当前的数据库状态和重写后的 AOF 文件保存的数据库状态不一致**。<br />为了解决上述问题，Redis 引入了 **AOF 重写缓冲区**（`**aof_rewrite_buf_blocks**`），这个缓冲区在服务器创建子进程之后开始使用，当 Redis 服务器**执行完一个写命令**之后，它会同时将这个**写命令追加到 AOF 缓冲区和 AOF 重写缓冲区**。<br />当子进程**完成 AOF 重写**工作后，父进程会在 serverCron 中检测到子进程已经重写结束，则会执行以下工作：<br />1、将 **AOF 重写缓冲区中的所有内容写入到新 AOF 文件**中，这时新 AOF 文件所保存的数据库状态将和服务器当前的**数据库状态一致**。<br />2、对新的 AOF 文件进行改名，原子的覆盖现有的 AOF 文件，完成新旧两个 AOF 文件的替换。
